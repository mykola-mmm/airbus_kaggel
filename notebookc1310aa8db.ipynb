{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9988,"databundleVersionId":868324,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# all imports\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nfrom PIL import Image\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers, Model, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-09T16:36:28.536839Z","iopub.execute_input":"2024-07-09T16:36:28.537670Z","iopub.status.idle":"2024-07-09T16:36:42.690177Z","shell.execute_reply.started":"2024-07-09T16:36:28.537635Z","shell.execute_reply":"2024-07-09T16:36:42.689394Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-09 16:36:31.424844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-09 16:36:31.424989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-09 16:36:31.568610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# aka env variables\nBASE_DIR = '/kaggle/input/airbus-ship-detection'\nTEST_IMG_DIR = os.path.join(BASE_DIR,'test_v2')\nTRAIN_IMG_DIR = os.path.join(BASE_DIR,'train_v2')\nTRAIN_DATASET_CSV = os.path.join(BASE_DIR,'train_ship_segmentations_v2.csv')\n\n########################################################################################\n\n# print(TEST_IMG)\n# print(TRAIN_IMG)\n# print(TRAIN_DATASE_CSV)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:36:42.691977Z","iopub.execute_input":"2024-07-09T16:36:42.692736Z","iopub.status.idle":"2024-07-09T16:36:42.698737Z","shell.execute_reply.started":"2024-07-09T16:36:42.692698Z","shell.execute_reply":"2024-07-09T16:36:42.697670Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# get train/test image list\ntrain_imgs = os.listdir(TRAIN_IMG_DIR)\ntest_imgs = os.listdir(TEST_IMG_DIR)\n\n# print(f\"{train_imgs[:10]}\")\n# print(f\"{test_imgs[:10]}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:36:42.700097Z","iopub.execute_input":"2024-07-09T16:36:42.700467Z","iopub.status.idle":"2024-07-09T16:36:44.432284Z","shell.execute_reply.started":"2024-07-09T16:36:42.700435Z","shell.execute_reply":"2024-07-09T16:36:44.431438Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# read dataset\ndf = pd.read_csv(TRAIN_DATASET_CSV)\ndf_backup = df\n\n# add info about ship beeing present in the image\ndf['has_ship'] = df['EncodedPixels'].apply(lambda x: 0 if pd.isna(x) else 1)\n\n# add info about total number of ships at the image\ndf['ship_count'] = df.groupby('ImageId')['EncodedPixels'].transform('count')\n\n# concat all EncodedPixels into AllEncodedPixels\ndf['AllEncodedPixels'] = df.groupby('ImageId')['EncodedPixels'].transform(\n    lambda x: np.nan if x.isna().all() else ' '.join(filter(None, x))\n)\n\n# remove repeating images\ndf = df.drop_duplicates(subset='ImageId', keep='first')\n\n# delete EncodedPixels column\ndf = df.drop(columns=['EncodedPixels'])\n\n# reset indexes\ndf = df.reset_index(drop=True)\n\n\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:36:44.434506Z","iopub.execute_input":"2024-07-09T16:36:44.434829Z","iopub.status.idle":"2024-07-09T16:37:21.218792Z","shell.execute_reply.started":"2024-07-09T16:36:44.434802Z","shell.execute_reply":"2024-07-09T16:37:21.217806Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         ImageId  has_ship  ship_count  \\\n0  00003e153.jpg         0           0   \n1  0001124c7.jpg         0           0   \n2  000155de5.jpg         1           1   \n3  000194a2d.jpg         1           5   \n4  0001b1832.jpg         0           0   \n\n                                    AllEncodedPixels  \n0                                                NaN  \n1                                                NaN  \n2  264661 17 265429 33 266197 33 266965 33 267733...  \n3  360486 1 361252 4 362019 5 362785 8 363552 10 ...  \n4                                                NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>has_ship</th>\n      <th>ship_count</th>\n      <th>AllEncodedPixels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00003e153.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001124c7.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000155de5.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000194a2d.jpg</td>\n      <td>1</td>\n      <td>5</td>\n      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001b1832.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# check the results of the previous operations\n\ntst = df[df['ImageId'] == '000194a2d.jpg']['AllEncodedPixels'].tolist()\nprint(tst)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:21.220076Z","iopub.execute_input":"2024-07-09T16:37:21.220542Z","iopub.status.idle":"2024-07-09T16:37:21.263829Z","shell.execute_reply.started":"2024-07-09T16:37:21.220504Z","shell.execute_reply":"2024-07-09T16:37:21.262688Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['360486 1 361252 4 362019 5 362785 8 363552 10 364321 10 365090 9 365858 10 366627 10 367396 9 368165 9 368933 10 369702 10 370471 9 371240 9 372009 9 372777 10 373546 9 374315 9 375084 7 375852 6 376621 3 377390 1 51834 9 52602 9 53370 9 54138 9 54906 9 55674 7 56442 7 57210 7 57978 7 58746 7 59514 7 60282 7 61050 9 61818 9 62586 9 63354 9 64122 9 64890 9 198320 10 199088 10 199856 10 200624 10 201392 10 202160 10 202928 10 203696 10 204464 10 205232 10 206000 10 206768 10 207536 10 208304 10 209072 10 209840 10 210608 10 211376 10 212144 10 212912 10 213680 10 214448 10 215216 10 215984 10 216751 10 217519 10 218287 10 219055 10 219823 10 220591 10 221359 10 222127 10 222895 10 223663 10 224431 10 225199 10 225967 10 226735 10 227503 10 228271 10 229039 10 229807 10 230575 10 231343 10 232111 10 232879 10 233647 10 234415 10 55683 1 56451 1 57219 1 57987 1 58755 1 59523 1 60291 1 254389 9 255157 17 255925 17 256693 17 257461 17 258229 17 258997 17 259765 17 260533 17 261301 17 262068 18 262836 17 263604 17 264372 17 265140 17 265908 17 266676 17 267444 17 268212 17 268980 17 269748 17 270516 17 271284 17 272052 17 272820 17 273588 17 274356 17 275124 17 275891 18 276659 17 277427 17 278195 17 278963 17 279731 17 280499 17 281267 17 282035 17 282803 17 283580 8']\n","output_type":"stream"}]},{"cell_type":"code","source":"# check distribution of ship_count per image\nplt.figure(figsize=(10,10))\nsns.countplot(x='ship_count', data=df, palette='viridis')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:21.265122Z","iopub.execute_input":"2024-07-09T16:37:21.265541Z","iopub.status.idle":"2024-07-09T16:37:21.654055Z","shell.execute_reply.started":"2024-07-09T16:37:21.265504Z","shell.execute_reply":"2024-07-09T16:37:21.653103Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"\nvalue_counts = df['ship_count'].value_counts()\nprint(value_counts)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:21.655355Z","iopub.execute_input":"2024-07-09T16:37:21.655655Z","iopub.status.idle":"2024-07-09T16:37:21.665502Z","shell.execute_reply.started":"2024-07-09T16:37:21.655630Z","shell.execute_reply":"2024-07-09T16:37:21.664478Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"ship_count\n0     150000\n1      27104\n2       7674\n3       2954\n4       1622\n5        925\n6        657\n7        406\n8        318\n9        243\n10       168\n11       144\n12       124\n14        76\n13        75\n15        66\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# balance dataset\nNUM_SAMPLES = 200\n# NUM_SAMPLES = value_counts.min()\n\nbalanced_df = pd.DataFrame()\n\nfor value in value_counts.index:\n    subset = df[df['ship_count'] == value]\n    number_samples = NUM_SAMPLES if NUM_SAMPLES < len(subset) else len(subset)\n#     print(f\"subset len - {len(subset)}\")\n    resampled_subset = resample(subset, replace=False, n_samples=number_samples, random_state=42)\n    balanced_df = pd.concat([balanced_df, resampled_subset])\n\n# drop images with less than 10 ships\n\nbalanced_df = balanced_df[balanced_df['ship_count'] >= 1]\n\n    \nplt.figure(figsize=(10,10))\nsns.countplot(x='ship_count', data=balanced_df, palette='viridis')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:21.666649Z","iopub.execute_input":"2024-07-09T16:37:21.666893Z","iopub.status.idle":"2024-07-09T16:37:22.062082Z","shell.execute_reply.started":"2024-07-09T16:37:21.666872Z","shell.execute_reply":"2024-07-09T16:37:22.061095Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# split train data into train and validation\ntrain_ids, validation_ids = train_test_split(\n    balanced_df, test_size = 0.2, stratify = balanced_df['ship_count'])\n\ntrain_df = pd.merge(balanced_df, train_ids)\nvalidation_df = pd.merge(balanced_df, validation_ids)\n\nprint(f\"train_df:\\n {train_df.sample(5)}\")\nprint(f\"validation_df:\\n {validation_df.sample(5)}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:22.063470Z","iopub.execute_input":"2024-07-09T16:37:22.064162Z","iopub.status.idle":"2024-07-09T16:37:22.096134Z","shell.execute_reply.started":"2024-07-09T16:37:22.064127Z","shell.execute_reply":"2024-07-09T16:37:22.095290Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"train_df:\n             ImageId  has_ship  ship_count  \\\n1924  4de149bd9.jpg         1          15   \n952   9a1c6fd32.jpg         1           6   \n1779  fb33f4eb1.jpg         1          12   \n899   b21940557.jpg         1           6   \n738   505558800.jpg         1           5   \n\n                                       AllEncodedPixels  \n1924  517904 1 518671 3 519438 5 520205 7 520972 9 5...  \n952   299988 2 300756 4 301523 6 302291 6 303058 6 3...  \n1779  501636 4 502405 3 503173 3 503941 3 504709 3 5...  \n899   309786 2 310552 4 311317 8 312083 10 312849 13...  \n738   471314 1 472081 4 472849 5 473616 8 474383 10 ...  \nvalidation_df:\n            ImageId  has_ship  ship_count  \\\n185  72e5ce016.jpg         1           5   \n447  dd831daba.jpg         1          12   \n417  e61c88e3b.jpg         1          11   \n99   3b1873681.jpg         1           3   \n266  51469b425.jpg         1           7   \n\n                                      AllEncodedPixels  \n185  395098 2 395864 4 396632 5 397400 5 398169 4 3...  \n447  509496 1 510263 3 511030 5 511797 7 512564 9 5...  \n417  311303 1 312070 3 312837 6 313604 8 314372 9 3...  \n99   309708 3 310470 9 311233 14 311998 17 312766 1...  \n266  297331 5 298095 9 298863 9 299631 9 300399 9 3...  \n","output_type":"stream"}]},{"cell_type":"code","source":"#utility functions\ndef rle_to_mask(starts, lengths, height, width):\n    # Create an empty array of zeros of shape (height, width)\n    mask = np.zeros(height * width, dtype=np.uint8)\n    \n    # For each start and length, set the corresponding values in the mask to 1\n    for start, length in zip(starts, lengths):\n        mask[start:start + length] = 1\n    \n    # Reshape the mask into the desired dimensions\n    mask = mask.reshape((height, width))\n    mask = mask.T\n    return mask\n\ndef create_mask(mask_array, width=768, height=768):\n    masks = np.zeros((width, height), dtype=np.int16)\n    # if element == element:\n    if isinstance(mask_array, str):\n        split = mask_array.split()\n        # print(split)\n        startP, lengthP = [np.array(x, dtype=int) for x in (split[::2], split[1::2])]\n        masks += (rle_to_mask(startP, lengthP, width, height))\n    return masks","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:22.099368Z","iopub.execute_input":"2024-07-09T16:37:22.099989Z","iopub.status.idle":"2024-07-09T16:37:22.108514Z","shell.execute_reply.started":"2024-07-09T16:37:22.099962Z","shell.execute_reply":"2024-07-09T16:37:22.107595Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# image generator\nBATCH_SIZE = 4\n\ndef img_gen(input_df, batch_size = BATCH_SIZE):\n    # shuffle the dataset\n    input_df = input_df.sample(frac=1, random_state=42).reset_index(drop=True)\n#     print(input_df.head())\n    out_rgb = []\n    out_mask = []\n    i = 1\n    while True:\n        for index, row in input_df.iterrows():\n            rgb_path = os.path.join(TRAIN_IMG_DIR, row.ImageId)\n            rgb = Image.open(rgb_path)\n            rgb = np.array(rgb)/255.0\n            mask = create_mask(row.AllEncodedPixels)\n            mask = np.expand_dims(mask, -1)\n#             print(f\"mask shape {mask.shape}\")\n#             print(f\"rgb shape {rgb.shape}\")\n            out_rgb += [rgb]\n            out_mask += [mask]\n            if len(out_rgb)>=batch_size:\n                yield np.stack(out_rgb, 0), np.stack(out_mask, 0).astype(np.float32)\n                out_rgb, out_mask=[], []\n\n# for index, row in df.iterrows():\n# img_gen(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:22.109825Z","iopub.execute_input":"2024-07-09T16:37:22.110203Z","iopub.status.idle":"2024-07-09T16:37:22.124402Z","shell.execute_reply.started":"2024-07-09T16:37:22.110160Z","shell.execute_reply":"2024-07-09T16:37:22.123499Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_gen = img_gen(train_df)\ntrain_x, train_y = next(train_gen)\nprint('x', train_x.shape, train_x.min(), train_x.max())\nprint('y', train_y.shape, train_y.min(), train_y.max())","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:22.125618Z","iopub.execute_input":"2024-07-09T16:37:22.126403Z","iopub.status.idle":"2024-07-09T16:37:22.266395Z","shell.execute_reply.started":"2024-07-09T16:37:22.126368Z","shell.execute_reply":"2024-07-09T16:37:22.265409Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"x (4, 768, 768, 3) 0.0 1.0\ny (4, 768, 768, 1) 0.0 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# create validation set\nVALIDATION_SET_SIZE = 100\n\nvalidation_x, validation_y = next(img_gen(validation_df, VALIDATION_SET_SIZE))","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:22.267693Z","iopub.execute_input":"2024-07-09T16:37:22.268014Z","iopub.status.idle":"2024-07-09T16:37:24.928989Z","shell.execute_reply.started":"2024-07-09T16:37:22.267987Z","shell.execute_reply":"2024-07-09T16:37:24.928107Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# data augmentation\n\n# arhuments for augmentation image generator\ndata_gen_args = dict(rotation_range = 90,\n                       horizontal_flip = True,\n                       vertical_flip = True,\n                       data_format = 'channels_last')\n\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\ndef augmentation_generator(input_gen, seed = None):\n    random_seed = np.random.randint(0, 10000)\n    for input_x, input_y in input_gen:\n        augmented_x = image_datagen.flow(\n            input_x*255,\n            batch_size=input_x.shape[0],\n            seed=random_seed\n        )\n\n        augmented_y = mask_datagen.flow(\n            input_y,\n            batch_size=input_y.shape[0],\n            seed=random_seed\n        )\n\n        yield next(augmented_x)/255.0, next(augmented_y)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:24.930146Z","iopub.execute_input":"2024-07-09T16:37:24.930536Z","iopub.status.idle":"2024-07-09T16:37:24.938086Z","shell.execute_reply.started":"2024-07-09T16:37:24.930510Z","shell.execute_reply":"2024-07-09T16:37:24.936943Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_fit_gen = augmentation_generator(train_gen)\n\n# train_gen = augmentation_generator(train_gen)\n# t_x, t_y = next(model_fit_gen)\n# print('x', t_x[0].shape, t_x.dtype, t_x.min(), t_x.max())\n# print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:24.939387Z","iopub.execute_input":"2024-07-09T16:37:24.939645Z","iopub.status.idle":"2024-07-09T16:37:24.948970Z","shell.execute_reply.started":"2024-07-09T16:37:24.939624Z","shell.execute_reply":"2024-07-09T16:37:24.948141Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# model\n\ndef unet(input_shape, optimizer, loss, metrics):\n    inputs = Input(input_shape)\n\n    # Encoder\n    c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n    c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n    p1 = layers.MaxPooling2D((2, 2)) (c1)\n\n    c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n    c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n    p2 = layers.MaxPooling2D((2, 2)) (c2)\n\n    c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n    c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n    p3 = layers.MaxPooling2D((2, 2)) (c3)\n\n    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n    p4 = layers.MaxPooling2D((2, 2)) (c4)\n\n    # Bottleneck\n    c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n    c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\n    # Decoder\n    u6 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = layers.concatenate([u6, c4])\n    c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n    c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n    u7 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = layers.concatenate([u7, c3])\n    c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n    c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n    u8 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = layers.concatenate([u8, c2])\n    c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n    c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n    u9 = layers.Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = layers.concatenate([u9, c1])\n    c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n    c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\n    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model\n\n\n# input_shape = (768, 768, 3)\n# model = unet(input_shape)\n# model.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:24.950029Z","iopub.execute_input":"2024-07-09T16:37:24.950318Z","iopub.status.idle":"2024-07-09T16:37:24.970800Z","shell.execute_reply.started":"2024-07-09T16:37:24.950288Z","shell.execute_reply":"2024-07-09T16:37:24.969963Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# loss functions\ndef dice_score(y_true, y_pred, smooth=1e-6):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3]  )\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_score(y_true, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:24.972029Z","iopub.execute_input":"2024-07-09T16:37:24.972460Z","iopub.status.idle":"2024-07-09T16:37:24.985093Z","shell.execute_reply.started":"2024-07-09T16:37:24.972426Z","shell.execute_reply":"2024-07-09T16:37:24.984229Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# callbacks\n\n\ntensorboard = TensorBoard(log_dir='logs')\n\nearlystopping = EarlyStopping(\n    monitor=\"val_dice_score\", \n    mode=\"max\", \n    patience=50) \n\ncheckpoint = ModelCheckpoint(\n    filepath='model.{epoch:02d}-{val_loss:.2f}.weights.h5',\n    monitor='val_dice_score',\n    verbose=1,\n    mode='max',\n    save_weights_only = True)\n\n\ncallbacks = [tensorboard, earlystopping, checkpoint]","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:24.986088Z","iopub.execute_input":"2024-07-09T16:37:24.986371Z","iopub.status.idle":"2024-07-09T16:37:24.995713Z","shell.execute_reply.started":"2024-07-09T16:37:24.986348Z","shell.execute_reply":"2024-07-09T16:37:24.994817Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# train model\n# TODO\nINPUT_DATA_DIM = (768,768,3)\nBATCH_SIZE = 40\nSTEP_COUNT = train_df.shape[0]//BATCH_SIZE\nNB_EPOCHS = 100\n\nprint(f\"train_df.shape[0] - {train_df.shape[0]}\")\nprint(f\"STEP COUNT - {STEP_COUNT}\")\n\nmodel = unet(INPUT_DATA_DIM, optimizer='adam', loss=dice_loss, metrics=[dice_score])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:24.996767Z","iopub.execute_input":"2024-07-09T16:37:24.997080Z","iopub.status.idle":"2024-07-09T16:37:25.952421Z","shell.execute_reply.started":"2024-07-09T16:37:24.997051Z","shell.execute_reply":"2024-07-09T16:37:25.951472Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"train_df.shape[0] - 1962\nSTEP COUNT - 49\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n\n input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,            \u001b[38;5;34m0\u001b[0m  -                 \n (\u001b[38;5;33mInputLayer\u001b[0m)         \u001b[38;5;34m3\u001b[0m)                                               \n\n conv2d (\u001b[38;5;33mConv2D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,          \u001b[38;5;34m224\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n                      \u001b[38;5;34m8\u001b[0m)                                               \n\n conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,          \u001b[38;5;34m584\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n                      \u001b[38;5;34m8\u001b[0m)                                               \n\n max_pooling2d        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,            \u001b[38;5;34m0\u001b[0m  conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n (\u001b[38;5;33mMaxPooling2D\u001b[0m)       \u001b[38;5;34m8\u001b[0m)                                               \n\n conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,        \u001b[38;5;34m1,168\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m] \n                      \u001b[38;5;34m16\u001b[0m)                                              \n\n conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,        \u001b[38;5;34m2,320\u001b[0m  conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n                      \u001b[38;5;34m16\u001b[0m)                                              \n\n max_pooling2d_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,            \u001b[38;5;34m0\u001b[0m  conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n (\u001b[38;5;33mMaxPooling2D\u001b[0m)       \u001b[38;5;34m16\u001b[0m)                                              \n\n conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,        \u001b[38;5;34m4,640\u001b[0m  max_pooling2d_1[\u001b[38;5;34m\u001b[0m \n                      \u001b[38;5;34m32\u001b[0m)                                              \n\n conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,        \u001b[38;5;34m9,248\u001b[0m  conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n                      \u001b[38;5;34m32\u001b[0m)                                              \n\n max_pooling2d_2      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,              \u001b[38;5;34m0\u001b[0m  conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n (\u001b[38;5;33mMaxPooling2D\u001b[0m)       \u001b[38;5;34m32\u001b[0m)                                              \n\n conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,         \u001b[38;5;34m18,496\u001b[0m  max_pooling2d_2[\u001b[38;5;34m\u001b[0m \n                      \u001b[38;5;34m64\u001b[0m)                                              \n\n conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,         \u001b[38;5;34m36,928\u001b[0m  conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n                      \u001b[38;5;34m64\u001b[0m)                                              \n\n max_pooling2d_3      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,              \u001b[38;5;34m0\u001b[0m  conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n (\u001b[38;5;33mMaxPooling2D\u001b[0m)       \u001b[38;5;34m64\u001b[0m)                                              \n\n conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,         \u001b[38;5;34m73,856\u001b[0m  max_pooling2d_3[\u001b[38;5;34m\u001b[0m \n                      \u001b[38;5;34m128\u001b[0m)                                             \n\n conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m,        \u001b[38;5;34m147,584\u001b[0m  conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n                      \u001b[38;5;34m128\u001b[0m)                                             \n\n conv2d_transpose     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,         \u001b[38;5;34m32,832\u001b[0m  conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m64\u001b[0m)                                              \n\n concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,              \u001b[38;5;34m0\u001b[0m  conv2d_transpose \n (\u001b[38;5;33mConcatenate\u001b[0m)        \u001b[38;5;34m128\u001b[0m)                           conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n\n conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,         \u001b[38;5;34m73,792\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n                      \u001b[38;5;34m64\u001b[0m)                                              \n\n conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m,         \u001b[38;5;34m36,928\u001b[0m  conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n                      \u001b[38;5;34m64\u001b[0m)                                              \n\n conv2d_transpose_1   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,        \u001b[38;5;34m8,224\u001b[0m  conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m32\u001b[0m)                                              \n\n concatenate_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,            \u001b[38;5;34m0\u001b[0m  conv2d_transpose \n (\u001b[38;5;33mConcatenate\u001b[0m)        \u001b[38;5;34m64\u001b[0m)                            conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n\n conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,       \u001b[38;5;34m18,464\u001b[0m  concatenate_1[\u001b[38;5;34m0\u001b[0m] \n                      \u001b[38;5;34m32\u001b[0m)                                              \n\n conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m,        \u001b[38;5;34m9,248\u001b[0m  conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n                      \u001b[38;5;34m32\u001b[0m)                                              \n\n conv2d_transpose_2   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,        \u001b[38;5;34m2,064\u001b[0m  conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m16\u001b[0m)                                              \n\n concatenate_2        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,            \u001b[38;5;34m0\u001b[0m  conv2d_transpose \n (\u001b[38;5;33mConcatenate\u001b[0m)        \u001b[38;5;34m32\u001b[0m)                            conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n\n conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,        \u001b[38;5;34m4,624\u001b[0m  concatenate_2[\u001b[38;5;34m0\u001b[0m] \n                      \u001b[38;5;34m16\u001b[0m)                                              \n\n conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,        \u001b[38;5;34m2,320\u001b[0m  conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n                      \u001b[38;5;34m16\u001b[0m)                                              \n\n conv2d_transpose_3   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,          \u001b[38;5;34m520\u001b[0m  conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m8\u001b[0m)                                               \n\n concatenate_3        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,            \u001b[38;5;34m0\u001b[0m  conv2d_transpose \n (\u001b[38;5;33mConcatenate\u001b[0m)        \u001b[38;5;34m16\u001b[0m)                            conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n\n conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,        \u001b[38;5;34m1,160\u001b[0m  concatenate_3[\u001b[38;5;34m0\u001b[0m] \n                      \u001b[38;5;34m8\u001b[0m)                                               \n\n conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,          \u001b[38;5;34m584\u001b[0m  conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n                      \u001b[38;5;34m8\u001b[0m)                                               \n\n conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m768\u001b[0m,            \u001b[38;5;34m9\u001b[0m  conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n                      \u001b[38;5;34m1\u001b[0m)                                               \n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n\n input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                               \n\n conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                               \n\n conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                               \n\n max_pooling2d        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                               \n\n conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n\n conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span>  conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n\n max_pooling2d_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n\n conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span>  max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n\n conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span>  conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n\n max_pooling2d_2      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n\n conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n\n conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span>  conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n\n max_pooling2d_3      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n\n conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span>  max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                             \n\n conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span>  conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                             \n\n conv2d_transpose     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span>  conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n\n concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n\n conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n\n conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span>  conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n\n conv2d_transpose_1   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span>  conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n\n concatenate_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                            conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n\n conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,       <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span>  concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n\n conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span>  conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n\n conv2d_transpose_2   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span>  conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n\n concatenate_2        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                            conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n\n conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n\n conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span>  conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                                              \n\n conv2d_transpose_3   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span>  conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                               \n\n concatenate_3        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose \n (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                            conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n\n conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,160</span>  concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                               \n\n conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span>  conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                                               \n\n conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>  conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                               \n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m485,817\u001b[0m (1.85 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">485,817</span> (1.85 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m485,817\u001b[0m (1.85 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">485,817</span> (1.85 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model_fit_gen = augmentation_generator(img_gen(train_df, BATCH_SIZE))\n# x, y = next(model_fit_gen)\n# print(f\"x.shape - {x.shape}\")\n# print(f\"validation_x.shape - {validation_x.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:25.953716Z","iopub.execute_input":"2024-07-09T16:37:25.954042Z","iopub.status.idle":"2024-07-09T16:37:25.958307Z","shell.execute_reply.started":"2024-07-09T16:37:25.954016Z","shell.execute_reply":"2024-07-09T16:37:25.957312Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    model_fit_gen,\n    steps_per_epoch=STEP_COUNT,\n    epochs=NB_EPOCHS,\n    validation_data=(validation_x, validation_y),\n    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:37:25.959439Z","iopub.execute_input":"2024-07-09T16:37:25.959722Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-07-09 16:37:52.186511: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:37:52.562942: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.78083, expected 2.84258\n2024-07-09 16:37:52.562998: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.66447, expected 4.72622\n2024-07-09 16:37:52.563007: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.40875, expected 4.47051\n2024-07-09 16:37:52.563015: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 4.77596, expected 3.83772\n2024-07-09 16:37:52.563023: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.63805, expected 4.69981\n2024-07-09 16:37:52.563031: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 6.44949, expected 5.51124\n2024-07-09 16:37:52.563039: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.78012, expected 5.84187\n2024-07-09 16:37:52.563046: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 6.16797, expected 5.22972\n2024-07-09 16:37:52.563054: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.36503, expected 4.42679\n2024-07-09 16:37:52.563062: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.20566, expected 4.26742\n2024-07-09 16:37:52.648592: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:37:52.648652: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:37:52.648667: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:37:52.648681: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:37:52.648694: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:37:52.648715: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:37:52.648779: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.462387248s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:37:55.234215: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:37:55.629621: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.78083, expected 2.84258\n2024-07-09 16:37:55.629673: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.66447, expected 4.72622\n2024-07-09 16:37:55.629682: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.40875, expected 4.47051\n2024-07-09 16:37:55.629690: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 4.77596, expected 3.83772\n2024-07-09 16:37:55.629698: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.63805, expected 4.69981\n2024-07-09 16:37:55.629706: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 6.44949, expected 5.51124\n2024-07-09 16:37:55.629713: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.78012, expected 5.84187\n2024-07-09 16:37:55.629721: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 6.16797, expected 5.22972\n2024-07-09 16:37:55.629729: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.36503, expected 4.42679\n2024-07-09 16:37:55.629736: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.20566, expected 4.26742\n2024-07-09 16:37:55.714418: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:37:55.714474: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:37:55.714484: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:37:55.714493: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:37:55.714501: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:37:55.714520: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:37:55.714568: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.480520447s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:37:58.625590: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:37:59.092126: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14155008: 7.70918, expected 6.83381\n2024-07-09 16:37:59.092193: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14155775: 6.35034, expected 5.47497\n2024-07-09 16:37:59.132010: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 23003136: 7.75211, expected 6.87674\n2024-07-09 16:37:59.153057: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 27721728: 7.14736, expected 6.27199\n2024-07-09 16:37:59.192781: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 37159679: 7.23883, expected 6.36345\n2024-07-09 16:37:59.212519: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 41877504: 6.52227, expected 5.6469\n2024-07-09 16:37:59.273159: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 56034047: 7.40299, expected 6.52762\n2024-07-09 16:37:59.276170: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 56623103: 7.17833, expected 6.30296\n2024-07-09 16:37:59.297847: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 61340928: 7.72235, expected 6.84698\n2024-07-09 16:37:59.316298: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65470464: 7.44758, expected 6.5722\n2024-07-09 16:37:59.400957: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:37:59.401008: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:37:59.401022: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:37:59.401033: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:37:59.401055: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:37:59.401077: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:37:59.401140: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.77565653s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:38:02.749202: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:38:03.191875: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14155008: 7.70918, expected 6.83381\n2024-07-09 16:38:03.191939: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14155775: 6.35034, expected 5.47497\n2024-07-09 16:38:03.228657: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 23003136: 7.75211, expected 6.87674\n2024-07-09 16:38:03.248184: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 27721728: 7.14736, expected 6.27199\n2024-07-09 16:38:03.287727: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 37159679: 7.23883, expected 6.36345\n2024-07-09 16:38:03.307386: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 41877504: 6.52227, expected 5.6469\n2024-07-09 16:38:03.368595: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 56034047: 7.40299, expected 6.52762\n2024-07-09 16:38:03.371371: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 56623103: 7.17833, expected 6.30296\n2024-07-09 16:38:03.391731: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 61340928: 7.72235, expected 6.84698\n2024-07-09 16:38:03.409616: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65470464: 7.44758, expected 6.5722\n2024-07-09 16:38:03.494596: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:38:03.494652: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:38:03.494670: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:38:03.494688: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:38:03.494699: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:38:03.494723: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:38:03.494787: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.745797239s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[40,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:38:06.432557: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1474560: 8.20605, expected 7.20657\n2024-07-09 16:38:06.432757: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1492991: 7.9858, expected 6.98632\n2024-07-09 16:38:06.432938: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1517567: 8.67305, expected 7.67358\n2024-07-09 16:38:06.433605: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1622015: 8.28202, expected 7.28254\n2024-07-09 16:38:06.435156: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1917311: 8.75836, expected 7.78043\n2024-07-09 16:38:06.443221: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3833856: 8.34449, expected 7.34501\n2024-07-09 16:38:06.443274: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3834239: 7.97704, expected 6.97756\n2024-07-09 16:38:06.443554: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3866879: 8.74527, expected 7.74579\n2024-07-09 16:38:06.443850: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3904511: 8.75134, expected 7.75186\n2024-07-09 16:38:06.444924: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4129151: 8.58882, expected 7.60785\n2024-07-09 16:38:06.488460: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[40,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:38:06.488504: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:38:06.488519: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:38:06.488530: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:38:06.488544: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:38:06.488571: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:38:08.010231: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1474560: 8.20605, expected 7.20657\n2024-07-09 16:38:08.010465: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1492991: 7.9858, expected 6.98632\n2024-07-09 16:38:08.010739: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1517567: 8.67305, expected 7.67358\n2024-07-09 16:38:08.011791: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1622015: 8.28202, expected 7.28254\n2024-07-09 16:38:08.013410: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1917311: 8.75836, expected 7.78043\n2024-07-09 16:38:08.022705: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3833856: 8.34449, expected 7.34501\n2024-07-09 16:38:08.022757: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3834239: 7.97704, expected 6.97756\n2024-07-09 16:38:08.022983: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3866879: 8.74527, expected 7.74579\n2024-07-09 16:38:08.023305: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3904511: 8.75134, expected 7.75186\n2024-07-09 16:38:08.024492: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4129151: 8.58882, expected 7.60785\n2024-07-09 16:38:08.070426: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[40,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:38:08.070474: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:38:08.070487: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:38:08.070498: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:38:08.070510: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:38:08.070537: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:38:53.130590: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[8,3,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:38:53.216284: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.085837807s\nTrying algorithm eng0{} for conv (f32[8,3,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:38:56.000845: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[8,3,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:38:56.074706: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.073994716s\nTrying algorithm eng0{} for conv (f32[8,3,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,3,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:00.473822: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[8,8,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:00.640837: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.167230583s\nTrying algorithm eng0{} for conv (f32[8,8,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:04.660489: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[8,8,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:04.819038: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.158729321s\nTrying algorithm eng0{} for conv (f32[8,8,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:25.056024: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,384,384]{3,2,1,0}, f32[40,16,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:25.435462: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.379617353s\nTrying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,384,384]{3,2,1,0}, f32[40,16,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:28.334113: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,384,384]{3,2,1,0}, f32[40,16,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:28.713235: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.379252526s\nTrying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,384,384]{3,2,1,0}, f32[40,16,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:36.714275: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[8,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,16,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:37.176467: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.46234696s\nTrying algorithm eng0{} for conv (f32[8,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,16,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:42.836747: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[8,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,16,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:43.299337: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.462782566s\nTrying algorithm eng0{} for conv (f32[8,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,16,768,768]{3,2,1,0}, f32[40,8,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:45.937565: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[1,8,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,1,768,768]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:46.023486: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.086026778s\nTrying algorithm eng0{} for conv (f32[1,8,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,1,768,768]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:48.450127: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[1,8,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,1,768,768]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:39:48.535793: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.085859112s\nTrying algorithm eng0{} for conv (f32[1,8,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,8,768,768]{3,2,1,0}, f32[40,1,768,768]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1720543191.915140     111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m49/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - dice_score: 0.0190 - loss: 0.9810","output_type":"stream"},{"name":"stderr","text":"2024-07-09 16:46:05.895992: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:05.982759: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.48343, expected 2.67507\n2024-07-09 16:46:05.982807: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.61589, expected 4.80753\n2024-07-09 16:46:05.982817: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 4.97192, expected 4.16356\n2024-07-09 16:46:05.982825: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 5.18467, expected 4.37631\n2024-07-09 16:46:05.982833: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.86768, expected 4.05932\n2024-07-09 16:46:05.982841: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.9059, expected 5.09754\n2024-07-09 16:46:05.982849: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.65475, expected 5.84639\n2024-07-09 16:46:05.982856: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.63801, expected 4.82964\n2024-07-09 16:46:05.982864: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.82892, expected 4.02055\n2024-07-09 16:46:05.982872: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.77212, expected 3.96375\n2024-07-09 16:46:06.050763: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:06.050813: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:06.050822: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:06.050830: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:06.050837: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:06.050855: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:06.050894: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.15505345s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:08.256458: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:08.395640: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.48343, expected 2.67507\n2024-07-09 16:46:08.395696: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.61589, expected 4.80753\n2024-07-09 16:46:08.395712: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 4.97192, expected 4.16356\n2024-07-09 16:46:08.395730: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 5.18467, expected 4.37631\n2024-07-09 16:46:08.395743: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.86768, expected 4.05932\n2024-07-09 16:46:08.395755: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.9059, expected 5.09754\n2024-07-09 16:46:08.395766: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.65475, expected 5.84639\n2024-07-09 16:46:08.395779: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.63801, expected 4.82964\n2024-07-09 16:46:08.395792: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.82892, expected 4.02055\n2024-07-09 16:46:08.395806: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.77212, expected 3.96375\n2024-07-09 16:46:08.463820: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:08.463870: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:08.463884: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:08.463894: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:08.463904: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:08.463925: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:08.463977: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.207639212s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:10.990399: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:11.354814: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 56623103: 6.277, expected 5.50055\n2024-07-09 16:46:11.450297: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 79627007: 6.4636, expected 5.68714\n2024-07-09 16:46:11.552688: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 103219967: 6.3939, expected 5.61744\n2024-07-09 16:46:11.828070: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:11.828129: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:11.828142: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:11.828159: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:11.828177: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:11.828198: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:11.828246: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.838000299s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:14.696524: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:15.031732: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 56623103: 6.277, expected 5.50055\n2024-07-09 16:46:15.129202: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 79627007: 6.4636, expected 5.68714\n2024-07-09 16:46:15.228339: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 103219967: 6.3939, expected 5.61744\n2024-07-09 16:46:15.499194: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:15.499249: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:15.499278: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:15.499291: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:15.499301: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:15.499324: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:15.499375: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.802994197s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-07-09 16:46:17.838156: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 147455: 6.97472, expected 6.14408\n2024-07-09 16:46:17.840500: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 589823: 7.11032, expected 6.29492\n2024-07-09 16:46:17.842205: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 884735: 7.46651, expected 6.58749\n2024-07-09 16:46:17.844695: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1179264: 8.54733, expected 7.55842\n2024-07-09 16:46:17.853308: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2211840: 8.35579, expected 7.36584\n2024-07-09 16:46:17.853358: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2212223: 7.19166, expected 6.20171\n2024-07-09 16:46:17.853540: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2230271: 8.37037, expected 7.38042\n2024-07-09 16:46:17.853862: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2254847: 8.47599, expected 7.48604\n2024-07-09 16:46:17.854910: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2358912: 8.38922, expected 7.39927\n2024-07-09 16:46:17.858969: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2802047: 7.09566, expected 6.28027\n2024-07-09 16:46:17.901862: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:17.901906: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:17.901924: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:17.901937: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:17.901948: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:17.901970: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:19.065908: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 147455: 6.97472, expected 6.14408\n2024-07-09 16:46:19.068024: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 589823: 7.11032, expected 6.29492\n2024-07-09 16:46:19.069419: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 884735: 7.46651, expected 6.58749\n2024-07-09 16:46:19.070762: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1179264: 8.54733, expected 7.55842\n2024-07-09 16:46:19.075416: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2211840: 8.35579, expected 7.36584\n2024-07-09 16:46:19.075456: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2212223: 7.19166, expected 6.20171\n2024-07-09 16:46:19.075626: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2230271: 8.37037, expected 7.38042\n2024-07-09 16:46:19.075875: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2254847: 8.47599, expected 7.48604\n2024-07-09 16:46:19.076561: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2358912: 8.38922, expected 7.39927\n2024-07-09 16:46:19.078486: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2802047: 7.09566, expected 6.28027\n2024-07-09 16:46:19.111951: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:19.111992: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:19.112008: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:19.112022: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:19.112033: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:19.112056: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:41.499504: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.5965, expected 2.86365\n2024-07-09 16:46:41.499563: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 4.9722, expected 4.23935\n2024-07-09 16:46:41.499572: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.56592, expected 4.83306\n2024-07-09 16:46:41.499580: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 4.30652, expected 3.57367\n2024-07-09 16:46:41.499588: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.83292, expected 4.10006\n2024-07-09 16:46:41.499596: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.92321, expected 5.19035\n2024-07-09 16:46:41.499603: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.04995, expected 5.3171\n2024-07-09 16:46:41.499611: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.55387, expected 4.82102\n2024-07-09 16:46:41.499619: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.24597, expected 4.51311\n2024-07-09 16:46:41.499627: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.29171, expected 3.55886\n2024-07-09 16:46:41.508608: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:41.508645: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:41.508659: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:41.508674: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:41.508686: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:41.508717: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:41.841009: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.5965, expected 2.86365\n2024-07-09 16:46:41.841063: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 4.9722, expected 4.23935\n2024-07-09 16:46:41.841073: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.56592, expected 4.83306\n2024-07-09 16:46:41.841081: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 4.30652, expected 3.57367\n2024-07-09 16:46:41.841089: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.83292, expected 4.10006\n2024-07-09 16:46:41.841098: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.92321, expected 5.19035\n2024-07-09 16:46:41.841106: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.04995, expected 5.3171\n2024-07-09 16:46:41.841114: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.55387, expected 4.82102\n2024-07-09 16:46:41.841122: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.24597, expected 4.51311\n2024-07-09 16:46:41.841130: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 4.29171, expected 3.55886\n2024-07-09 16:46:41.850208: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,3,768,768]{3,2,1,0}, f32[8,3,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-07-09 16:46:41.850245: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:41.850262: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:41.850270: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:41.850295: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:41.850311: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:42.216507: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:42.248488: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:42.251205: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:42.284826: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=7}\n2024-07-09 16:46:42.284869: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:42.284877: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:42.284884: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:42.284892: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:42.284908: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:42.444895: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:42.477032: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:42.479729: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:42.514138: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=0}\n2024-07-09 16:46:42.514177: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:42.514186: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:42.514194: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:42.514201: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:42.514219: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:42.672925: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:42.704469: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:42.706950: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:42.740396: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=8}\n2024-07-09 16:46:42.740439: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:42.740448: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:42.740456: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:42.740464: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:42.740481: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:42.903847: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:42.935717: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:42.938263: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:42.971242: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=5}\n2024-07-09 16:46:42.971286: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:42.971295: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:42.971302: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:42.971309: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:42.971324: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:43.132140: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:43.164587: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:43.167036: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:43.200532: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=3}\n2024-07-09 16:46:43.200568: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:43.200577: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:43.200584: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:43.200591: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:43.200607: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:43.367236: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:43.399465: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:43.401946: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:43.437074: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=4}\n2024-07-09 16:46:43.437115: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:43.437124: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:43.437132: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:43.437139: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:43.437155: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:43.600268: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:43.632245: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:43.634984: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:43.668122: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:43.668167: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:43.668177: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:43.668186: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:43.668194: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:43.668213: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:43.835558: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:43.868083: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:43.870760: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:43.905653: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=3,k5=1,k6=0,k7=0}\n2024-07-09 16:46:43.905698: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:43.905708: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:43.905716: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:43.905723: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:43.905740: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:44.067828: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:44.100092: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:44.102580: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:44.135759: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:44.135799: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:44.135808: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:44.135815: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:44.135822: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:44.135838: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:44.297519: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:44.329229: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:44.331778: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:44.365104: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:44.365144: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:44.365153: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:44.365167: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:44.365175: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:44.365191: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:44.540304: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:44.571932: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:44.574687: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:44.607910: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=0,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:44.607950: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:44.607960: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:44.607968: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:44.607976: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:44.607994: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:44.790242: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:44.822436: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:44.825054: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:44.859398: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=2,k3=0}\n2024-07-09 16:46:44.859443: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:44.859452: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:44.859460: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:44.859467: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:44.859483: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:45.022975: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:45.054735: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:45.057303: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:45.091528: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=4,k3=0}\n2024-07-09 16:46:45.091567: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:45.091576: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:45.091583: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:45.091590: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:45.091606: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:45.279210: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:45.311927: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.9175\n2024-07-09 16:46:45.314539: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:45.348059: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng14{}\n2024-07-09 16:46:45.348105: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:45.348117: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:45.348125: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:45.348134: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:45.348152: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:45.514639: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:45.545899: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:45.548675: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:45.581457: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=4,k3=0}\n2024-07-09 16:46:45.581496: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:45.581504: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:45.581511: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:45.581518: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:45.581534: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:45.748985: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:45.782092: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:45.784778: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:45.818227: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=3,k3=0}\n2024-07-09 16:46:45.818285: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:45.818295: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:45.818304: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:45.818312: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:45.818329: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:45.983016: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:46.014641: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:46.017093: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:46.049939: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng11{k2=4,k3=0}\n2024-07-09 16:46:46.049976: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:46.049985: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:46.049993: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:46.050000: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:46.050015: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:46.237096: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:46.269369: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:46.271939: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:46.305372: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng0{}\n2024-07-09 16:46:46.305412: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:46.305421: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:46.305428: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:46.305436: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:46.305451: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:46.473849: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:46.505902: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:46.508541: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:46.541488: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=7}\n2024-07-09 16:46:46.541526: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:46.541535: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:46.541542: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:46.541549: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:46.541565: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:46.700364: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:46.731353: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:46.733972: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:46.767990: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=0}\n2024-07-09 16:46:46.768055: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:46.768064: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:46.768072: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:46.768080: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:46.768114: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:46.928134: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:46.960842: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:46.963679: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:46.997259: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=8}\n2024-07-09 16:46:46.997313: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:46.997321: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:46.997329: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:46.997336: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:46.997351: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:47.157067: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:47.188848: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:47.191527: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:47.224608: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=5}\n2024-07-09 16:46:47.224645: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:47.224654: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:47.224661: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:47.224668: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:47.224684: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:47.383685: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:47.415340: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:47.417802: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:47.453086: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=3}\n2024-07-09 16:46:47.453127: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:47.453137: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:47.453144: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:47.453151: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:47.453167: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:47.620065: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:47.654086: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:47.656795: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:47.695884: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=4}\n2024-07-09 16:46:47.695930: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:47.695939: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:47.695947: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:47.695955: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:47.695973: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:47.869971: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:47.904998: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:47.907643: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:47.941170: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:47.941217: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:47.941229: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:47.941241: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:47.941268: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:47.941289: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:48.105133: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:48.136812: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:48.139543: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:48.173060: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=3,k5=1,k6=0,k7=0}\n2024-07-09 16:46:48.173101: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:48.173115: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:48.173127: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:48.173143: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:48.173166: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:48.330292: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:48.362127: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:48.364671: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:48.398143: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:48.398187: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:48.398201: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:48.398233: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:48.398248: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:48.398300: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:48.557465: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:48.588811: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:48.591426: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:48.624685: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:48.624731: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:48.624744: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:48.624755: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:48.624771: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:48.624791: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:48.798637: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:48.830512: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:48.833100: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:48.866635: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=0,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:48.866678: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:48.866692: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:48.866704: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:48.866721: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:48.866742: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:49.047051: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:49.078721: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:49.081397: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:49.114245: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=2,k3=0}\n2024-07-09 16:46:49.114300: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:49.114315: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:49.114330: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:49.114344: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:49.114368: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:49.279429: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:49.311618: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:49.314380: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:49.347378: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=4,k3=0}\n2024-07-09 16:46:49.347419: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:49.347432: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:49.347443: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:49.347459: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:49.347480: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:49.537922: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:49.569986: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.9175\n2024-07-09 16:46:49.572562: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:49.606211: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng14{}\n2024-07-09 16:46:49.606268: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:49.606286: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:49.606303: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:49.606313: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:49.606335: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:49.773391: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:49.805714: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:49.808232: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:49.842383: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=4,k3=0}\n2024-07-09 16:46:49.842429: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:49.842444: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:49.842460: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:49.842471: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:49.842492: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:50.006640: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:50.038616: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:50.041326: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:50.074517: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=3,k3=0}\n2024-07-09 16:46:50.074560: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:50.074575: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:50.074588: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:50.074606: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:50.074630: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:50.238557: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:50.271375: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:50.273969: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:50.307767: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng11{k2=4,k3=0}\n2024-07-09 16:46:50.307809: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:50.307823: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:50.307836: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:50.307850: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:50.307871: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:50.499282: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4718592: 6.23921, expected 7.06518\n2024-07-09 16:46:50.531094: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12387071: 7.00439, expected 7.91751\n2024-07-09 16:46:50.533642: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12976127: 6.95521, expected 7.86833\n2024-07-09 16:46:50.566608: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,8,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,768,768]{3,2,1,0}, f32[8,8,3,3]{3,2,1,0}, f32[8]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng0{}\n2024-07-09 16:46:50.566650: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:50.566664: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:50.566678: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:50.566692: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:50.566714: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:50.672737: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:50.691755: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:50.709675: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=7}\n2024-07-09 16:46:50.709729: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:50.709744: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:50.709755: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:50.709766: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:50.709786: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:50.788291: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:50.807264: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:50.825038: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=0}\n2024-07-09 16:46:50.825078: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:50.825091: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:50.825103: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:50.825118: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:50.825140: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:50.902403: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:50.921447: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:50.938836: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=8}\n2024-07-09 16:46:50.938881: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:50.938896: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:50.938909: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:50.938927: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:50.938951: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.014605: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.033615: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.051462: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=5}\n2024-07-09 16:46:51.051504: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.051521: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.051536: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.051551: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.051573: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.128765: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.149520: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.168449: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=3}\n2024-07-09 16:46:51.168491: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.168507: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.168539: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.168557: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.168581: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.247033: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.265911: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.283473: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=4}\n2024-07-09 16:46:51.283513: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.283526: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.283538: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.283553: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.283573: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.360373: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.380104: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.397478: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:51.397524: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.397538: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.397553: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.397566: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.397587: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.476477: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.495671: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.513170: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=3,k5=1,k6=0,k7=0}\n2024-07-09 16:46:51.513212: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.513225: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.513238: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.513263: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.513285: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.589196: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.608425: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.625889: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:51.625927: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.625939: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.625950: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.625966: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.625987: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.701604: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.721031: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.738912: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:51.738966: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.738985: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.739003: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.739019: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.739043: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.821532: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.840834: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.858402: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=0,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:51.858440: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.858456: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.858470: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.858481: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.858502: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:51.941005: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:51.959970: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:51.977350: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=2,k3=0}\n2024-07-09 16:46:51.977392: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:51.977404: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:51.977415: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:51.977429: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:51.977451: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.054083: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.073048: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.090630: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=4,k3=0}\n2024-07-09 16:46:52.090670: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.090682: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.090698: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.090709: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.090730: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.183750: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.202911: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98179\n2024-07-09 16:46:52.220946: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng14{}\n2024-07-09 16:46:52.220990: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.221005: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.221020: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.221035: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.221055: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.299471: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.318453: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.336170: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=4,k3=0}\n2024-07-09 16:46:52.336211: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.336225: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.336238: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.336262: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.336285: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.414351: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.433073: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.452213: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=3,k3=0}\n2024-07-09 16:46:52.452247: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.452278: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.452289: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.452299: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.452321: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.529247: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.548013: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.565683: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng11{k2=4,k3=0}\n2024-07-09 16:46:52.565726: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.565741: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.565758: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.565773: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.565797: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.653766: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.673091: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.690526: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng13{}\n2024-07-09 16:46:52.690563: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.690576: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.690594: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.690604: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.690625: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.785377: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.804440: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.822482: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng0{}\n2024-07-09 16:46:52.822526: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.822540: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.822555: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.822568: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.822589: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:52.902461: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:52.921477: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:52.939283: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=7}\n2024-07-09 16:46:52.939326: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:52.939342: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:52.939360: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:52.939373: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:52.939396: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.017173: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.038295: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.057288: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=0}\n2024-07-09 16:46:53.057328: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.057341: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.057353: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.057368: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.057391: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.133619: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.152662: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.170854: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=8}\n2024-07-09 16:46:53.170905: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.170922: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.170941: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.170956: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.170979: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.248468: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.267407: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.284993: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=5}\n2024-07-09 16:46:53.285032: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.285044: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.285056: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.285072: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.285092: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.363054: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.382590: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.400243: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=3}\n2024-07-09 16:46:53.400293: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.400305: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.400317: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.400333: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.400354: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.479670: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.498331: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.515892: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng15{k5=1,k6=0,k7=1,k10=4}\n2024-07-09 16:46:53.515930: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.515944: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.515958: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.515970: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.515991: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.593669: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.613088: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.630816: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:53.630857: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.630870: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.630886: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.630897: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.630919: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.708380: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.727405: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.746229: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=1,k4=3,k5=1,k6=0,k7=0}\n2024-07-09 16:46:53.746280: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.746295: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.746313: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.746326: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.746349: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.825063: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.844570: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.862401: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=1,k5=1,k6=0,k7=0}\n2024-07-09 16:46:53.862439: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.862451: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.862463: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.862477: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.862500: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:53.939270: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:53.958973: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:53.977046: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=2,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:53.977085: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:53.977097: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:53.977109: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:53.977125: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:53.977146: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.056757: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.075807: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.093204: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng20{k2=0,k4=2,k5=1,k6=0,k7=0}\n2024-07-09 16:46:54.093243: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.093264: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.093281: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.093291: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.093311: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.174977: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.195405: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.212967: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=2,k3=0}\n2024-07-09 16:46:54.213009: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.213021: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.213032: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.213048: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.213070: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.291463: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.310574: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.328211: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng35{k2=4,k3=0}\n2024-07-09 16:46:54.328262: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.328277: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.328294: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.328312: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.328335: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.420348: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.439435: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98179\n2024-07-09 16:46:54.458359: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng14{}\n2024-07-09 16:46:54.458400: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.458413: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.458429: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.458440: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.458460: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.536853: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.555816: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.573411: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=4,k3=0}\n2024-07-09 16:46:54.573449: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.573461: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.573473: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.573488: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.573509: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.651104: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.670221: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.687788: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng36{k2=3,k3=0}\n2024-07-09 16:46:54.687828: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.687843: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.687856: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.687865: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.687887: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.765678: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.785622: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.803116: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng11{k2=4,k3=0}\n2024-07-09 16:46:54.803159: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.803178: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.803193: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.803204: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.803223: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:54.892041: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:54.911093: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:54.928371: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng13{}\n2024-07-09 16:46:54.928408: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:54.928421: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:54.928432: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:54.928447: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:54.928469: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-07-09 16:46:55.023364: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1769471: 5.84141, expected 6.67954\n2024-07-09 16:46:55.043080: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6340991: 6.14365, expected 6.98178\n2024-07-09 16:46:55.061233: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[4,16,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,8,384,384]{3,2,1,0}, f32[16,8,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng15{k5=1,k6=0,k7=1,k10=1} vs eng0{}\n2024-07-09 16:46:55.061278: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-07-09 16:46:55.061292: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-07-09 16:46:55.061308: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n2024-07-09 16:46:55.061319: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-07-09 16:46:55.061342: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: saving model to model.01-0.79.weights.h5\n\u001b[1m49/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 9s/step - dice_score: 0.0194 - loss: 0.9806 - val_dice_score: 0.2547 - val_loss: 0.7898\nEpoch 2/100\n\u001b[1m49/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - dice_score: 0.0862 - loss: 0.9138\nEpoch 2: saving model to model.02-0.98.weights.h5\n\u001b[1m49/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 7s/step - dice_score: 0.0852 - loss: 0.9148 - val_dice_score: 0.0197 - val_loss: 0.9790\nEpoch 3/100\n\u001b[1m49/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - dice_score: 0.0151 - loss: 0.9849\nEpoch 3: saving model to model.03-0.98.weights.h5\n\u001b[1m49/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 7s/step - dice_score: 0.0151 - loss: 0.9849 - val_dice_score: 0.0197 - val_loss: 0.9790\nEpoch 4/100\n\u001b[1m32/49\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2:11\u001b[0m 8s/step - dice_score: 0.0152 - loss: 0.9848","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}