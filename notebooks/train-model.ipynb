{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33429c30",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-26T19:19:04.039189Z",
     "iopub.status.busy": "2024-07-26T19:19:04.038533Z",
     "iopub.status.idle": "2024-07-26T19:19:09.696522Z",
     "shell.execute_reply": "2024-07-26T19:19:09.695475Z"
    },
    "papermill": {
     "duration": 5.664292,
     "end_time": "2024-07-26T19:19:09.698897",
     "exception": false,
     "start_time": "2024-07-26T19:19:04.034605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'airbus_kaggel'...\r\n",
      "remote: Enumerating objects: 186, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Total 186 (delta 16), reused 10 (delta 4), pack-reused 155\u001b[K\r\n",
      "Receiving objects: 100% (186/186), 99.99 MiB | 34.43 MiB/s, done.\r\n",
      "Resolving deltas: 100% (85/85), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mykola-mmm/airbus_kaggel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fe6b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T19:19:09.708663Z",
     "iopub.status.busy": "2024-07-26T19:19:09.707982Z",
     "iopub.status.idle": "2024-07-26T19:19:09.712307Z",
     "shell.execute_reply": "2024-07-26T19:19:09.711522Z"
    },
    "papermill": {
     "duration": 0.011069,
     "end_time": "2024-07-26T19:19:09.714166",
     "exception": false,
     "start_time": "2024-07-26T19:19:09.703097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./airbus_kaggel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f227bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T19:19:09.722659Z",
     "iopub.status.busy": "2024-07-26T19:19:09.722230Z",
     "iopub.status.idle": "2024-07-26T19:19:11.264254Z",
     "shell.execute_reply": "2024-07-26T19:19:11.263054Z"
    },
    "papermill": {
     "duration": 1.548897,
     "end_time": "2024-07-26T19:19:11.266760",
     "exception": false,
     "start_time": "2024-07-26T19:19:09.717863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'v2' set up to track remote branch 'v2' from 'origin'.\r\n",
      "Switched to a new branch 'v2'\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b222fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T19:19:11.277821Z",
     "iopub.status.busy": "2024-07-26T19:19:11.277460Z",
     "iopub.status.idle": "2024-07-26T19:19:12.294160Z",
     "shell.execute_reply": "2024-07-26T19:19:12.293087Z"
    },
    "papermill": {
     "duration": 1.025058,
     "end_time": "2024-07-26T19:19:12.296431",
     "exception": false,
     "start_time": "2024-07-26T19:19:11.271373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1635046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T19:19:12.306294Z",
     "iopub.status.busy": "2024-07-26T19:19:12.305977Z",
     "iopub.status.idle": "2024-07-26T19:34:19.342855Z",
     "shell.execute_reply": "2024-07-26T19:34:19.341718Z"
    },
    "papermill": {
     "duration": 907.044496,
     "end_time": "2024-07-26T19:34:19.345286",
     "exception": false,
     "start_time": "2024-07-26T19:19:12.300790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 19:19:16.677726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-07-26 19:19:16.677860: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-07-26 19:19:16.873443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Number of devices: 2\r\n",
      "The size of the training set: 1342\r\n",
      "The size of the validation set: 336\r\n",
      "Steps/Epoch: 83\r\n",
      "<class 'function'>\r\n",
      "\u001b[1mModel: \"functional\"\u001b[0m\r\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\r\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\r\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\r\n",
      "│ keras_tensor_2CLONE │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ -                 │\r\n",
      "│ (\u001b[94mInputLayer\u001b[0m)        │ \u001b[32m3\u001b[0m)                │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d (\u001b[94mConv2D\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │        \u001b[32m448\u001b[0m │ keras_tensor_2CL… │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]      │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m2,320\u001b[0m │ dropout[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]     │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d       │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_1[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m4,640\u001b[0m │ max_pooling2d[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_1 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_2[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m9,248\u001b[0m │ dropout_1[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d_1     │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_3[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_4 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m18,496\u001b[0m │ max_pooling2d_1[\u001b[32m…\u001b[0m │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_2 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_4[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_5 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m36,928\u001b[0m │ dropout_2[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d_2     │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_5[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_6 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │     \u001b[32m73,856\u001b[0m │ max_pooling2d_2[\u001b[32m…\u001b[0m │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_3 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_6[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_7 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m147,584\u001b[0m │ dropout_3[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d_3     │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_7[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_8 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │    \u001b[32m295,168\u001b[0m │ max_pooling2d_3[\u001b[32m…\u001b[0m │\r\n",
      "│                     │ \u001b[32m256\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_4 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_8[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m256\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_9 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │    \u001b[32m590,080\u001b[0m │ dropout_4[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m256\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose    │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m131,200\u001b[0m │ conv2d_9[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m256\u001b[0m)              │            │ conv2d_7[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_10 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m295,040\u001b[0m │ concatenate[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m] │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_5 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_10[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_11 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m147,584\u001b[0m │ dropout_5[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose_1  │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m32,832\u001b[0m │ conv2d_11[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m128\u001b[0m)              │            │ conv2d_5[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_12 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m73,792\u001b[0m │ concatenate_1[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_6 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_12[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_13 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m36,928\u001b[0m │ dropout_6[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose_2  │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m8,224\u001b[0m │ conv2d_13[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m64\u001b[0m)               │            │ conv2d_3[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_14 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │     \u001b[32m18,464\u001b[0m │ concatenate_2[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_7 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_14[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_15 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m9,248\u001b[0m │ dropout_7[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose_3  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m2,064\u001b[0m │ conv2d_15[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m32\u001b[0m)               │            │ conv2d_1[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_16 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m4,624\u001b[0m │ concatenate_3[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_8 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_16[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_17 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m2,320\u001b[0m │ dropout_8[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_18 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │         \u001b[32m17\u001b[0m │ conv2d_17[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m1\u001b[0m)                │            │                   │\r\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\r\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m1,941,105\u001b[0m (7.40 MB)\r\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m1,941,105\u001b[0m (7.40 MB)\r\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\r\n",
      "Epoch 1/300\r\n",
      "2024-07-26 19:22:14.148940: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:14.152094: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.003266996s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:18.635444: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:18.646584: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.011275478s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:28.445026: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:28.504814: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.059906073s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:34.784772: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:34.862894: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.078213364s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:39.425537: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:39.571641: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.146182002s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:42.697420: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:42.847377: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.150039207s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:47.187046: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:47.962248: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.775309083s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:51.352714: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:22:52.138415: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.785807783s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:27.664208: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:28.252035: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.587923163s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:31.862349: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:32.436691: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.574514619s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:38.609630: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:39.074836: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.46536502s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:41.461429: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:23:41.934786: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.473485122s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:06.244704: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:08.361873: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.117269535s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:11.824406: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:13.973700: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.149414148s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:20.594829: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:20.650520: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.055793432s\r\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:21.650725: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:24.070188: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.419566684s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:28.415933: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:28.471710: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.055921954s\r\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:29.471896: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:24:31.890100: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.418302483s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "I0000 00:00:1722021881.673830      88 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9664 - dice_score: 0.0120 - loss: 1.16602024-07-26 19:32:05.182721: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:05.331785: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.149148553s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:11.988362: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:12.157623: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.169435971s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:23.390529: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:23.462612: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.072308484s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:28.356362: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:32:28.416348: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.060110326s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:20.421122: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:21.546582: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.125554962s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:28.033118: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:29.170442: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.137417049s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:31.754396: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:32.075217: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.320917543s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:34.225856: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:34.554190: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.328438255s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:42.956707: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:43.128275: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.171668376s\r\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:44.128503: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:44.873057: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.74468564s\r\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:45.873253: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:47.065035: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.191883557s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:54.262485: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:54.429903: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.167533096s\r\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:55.430095: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:56.167673: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.737676983s\r\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:57.167934: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 19:33:58.342757: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.174991207s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "\r\n",
      "Epoch 1: saving model to models/model.epoch01-val_dice_score0.000.keras\r\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 7s/step - accuracy: 0.9666 - dice_score: 0.0121 - loss: 1.1654 - val_accuracy: 0.9919 - val_dice_score: 1.6423e-09 - val_loss: 1.1257 - learning_rate: 0.0010\r\n",
      "Epoch 2/300\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/airbus_kaggel/./train-model.py\", line 197, in <module>\r\n",
      "    loss_history = [model.fit(model_fit_gen,\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\r\n",
      "    raise e.with_traceback(filtered_tb) from None\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\r\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\r\n",
      "\r\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\r\n",
      "  File \"/kaggle/working/airbus_kaggel/./train-model.py\", line 197, in <module>\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\r\n",
      "\r\n",
      "Out of memory while trying to allocate 12287693816 bytes.\r\n",
      "BufferAssignment OOM Debugging.\r\n",
      "BufferAssignment stats:\r\n",
      "             parameter allocation:  166.21MiB\r\n",
      "              constant allocation:        32B\r\n",
      "        maybe_live_out allocation:   22.21MiB\r\n",
      "     preallocated temp allocation:   11.44GiB\r\n",
      "  preallocated temp fragmentation:  867.92MiB (7.41%)\r\n",
      "                 total allocation:   11.61GiB\r\n",
      "              total fragmentation:  883.56MiB (7.43%)\r\n",
      "Peak buffers:\r\n",
      "\tBuffer 1:\r\n",
      "\t\tSize: 1.12GiB\r\n",
      "\t\tOperator: op_type=\"ConcatV2\" op_name=\"functional_1/concatenate_3_1/concat\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,32,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 2:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 3:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/functional_1/conv2d_18_1/convolution/Conv2DBackpropInput\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 4:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_17_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 5:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"SelectV2\" op_name=\"functional_1/dropout_8_1/stateless_dropout/SelectV2\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160 deduplicated_name=\"fusion.208\"\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 6:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_16_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 7:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"ConcatV2\" op_name=\"functional_1/concatenate_2_1/concat\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,64,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 8:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 9:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"SelectV2\" op_name=\"functional_1/dropout_1/stateless_dropout/SelectV2\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160 deduplicated_name=\"fusion.208\"\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 10:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 11:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_15_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 12:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"SelectV2\" op_name=\"functional_1/dropout_7_1/stateless_dropout/SelectV2\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160 deduplicated_name=\"fusion.210\"\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 13:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_14_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 14:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"ConcatV2\" op_name=\"functional_1/concatenate_1_2/concat\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,128,192,192]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 15:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_3_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\r\n",
      "\t [[{{node StatefulPartitionedCall}}]]\r\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n",
      " [Op:__inference_one_step_on_iterator_9103]\r\n",
      "2024-07-26 19:34:18.878343: F external/local_tsl/tsl/framework/bfc_allocator.cc:700] Check failed: h != kInvalidChunkHandle \r\n"
     ]
    }
   ],
   "source": [
    "!python ./train-model.py --csv_file /kaggle/input/airbus-kaggle-preprocessed/df.csv --dataset_path /kaggle/input/airbus-ship-detection/train_v2 --max_number_of_samples 2500 --epochs 300 --batch_size 16 --loss_function dice_bce_loss --patch_size 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2537a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T19:34:19.381861Z",
     "iopub.status.busy": "2024-07-26T19:34:19.380979Z",
     "iopub.status.idle": "2024-07-26T19:34:20.385588Z",
     "shell.execute_reply": "2024-07-26T19:34:20.384441Z"
    },
    "papermill": {
     "duration": 1.02523,
     "end_time": "2024-07-26T19:34:20.387856",
     "exception": false,
     "start_time": "2024-07-26T19:34:19.362626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 49596\r\n",
      "drwxr-xr-x 7 root root     4096 Jul 26 19:21 .\r\n",
      "drwxr-xr-x 3 root root     4096 Jul 26 19:19 ..\r\n",
      "drwxr-xr-x 8 root root     4096 Jul 26 19:19 .git\r\n",
      "-rw-r--r-- 1 root root       43 Jul 26 19:19 .gitignore\r\n",
      "-rw-r--r-- 1 root root     5040 Jul 26 19:19 README.md\r\n",
      "-rw-r--r-- 1 root root 50719787 Jul 26 19:19 df.csv\r\n",
      "drwxr-xr-x 4 root root     4096 Jul 26 19:31 logs\r\n",
      "drwxr-xr-x 2 root root     4096 Jul 26 19:34 models\r\n",
      "drwxr-xr-x 2 root root     4096 Jul 26 19:19 notebooks\r\n",
      "-rw-r--r-- 1 root root      128 Jul 26 19:19 requirements.txt\r\n",
      "-rw-r--r-- 1 root root     2878 Jul 26 19:19 test-model.py\r\n",
      "-rw-r--r-- 1 root root    13222 Jul 26 19:19 train-model.py\r\n",
      "drwxr-xr-x 3 root root     4096 Jul 26 19:19 utils\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 868324,
     "sourceId": 9988,
     "sourceType": "competition"
    },
    {
     "datasetId": 5450343,
     "sourceId": 9040735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 919.637958,
   "end_time": "2024-07-26T19:34:20.625437",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-26T19:19:00.987479",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
