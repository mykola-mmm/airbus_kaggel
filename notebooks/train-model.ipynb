{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fd63d5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-26T20:10:19.308781Z",
     "iopub.status.busy": "2024-07-26T20:10:19.308224Z",
     "iopub.status.idle": "2024-07-26T20:10:25.032759Z",
     "shell.execute_reply": "2024-07-26T20:10:25.031777Z"
    },
    "papermill": {
     "duration": 5.73111,
     "end_time": "2024-07-26T20:10:25.035277",
     "exception": false,
     "start_time": "2024-07-26T20:10:19.304167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'airbus_kaggel'...\r\n",
      "remote: Enumerating objects: 190, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (35/35), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (31/31), done.\u001b[K\r\n",
      "remote: Total 190 (delta 19), reused 10 (delta 4), pack-reused 155\u001b[K\r\n",
      "Receiving objects: 100% (190/190), 99.99 MiB | 34.03 MiB/s, done.\r\n",
      "Resolving deltas: 100% (88/88), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mykola-mmm/airbus_kaggel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6411c959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T20:10:25.045008Z",
     "iopub.status.busy": "2024-07-26T20:10:25.044253Z",
     "iopub.status.idle": "2024-07-26T20:10:25.048647Z",
     "shell.execute_reply": "2024-07-26T20:10:25.047839Z"
    },
    "papermill": {
     "duration": 0.011118,
     "end_time": "2024-07-26T20:10:25.050473",
     "exception": false,
     "start_time": "2024-07-26T20:10:25.039355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./airbus_kaggel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e9b839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T20:10:25.058658Z",
     "iopub.status.busy": "2024-07-26T20:10:25.058409Z",
     "iopub.status.idle": "2024-07-26T20:10:26.637069Z",
     "shell.execute_reply": "2024-07-26T20:10:26.636133Z"
    },
    "papermill": {
     "duration": 1.585078,
     "end_time": "2024-07-26T20:10:26.639195",
     "exception": false,
     "start_time": "2024-07-26T20:10:25.054117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'v2' set up to track remote branch 'v2' from 'origin'.\r\n",
      "Switched to a new branch 'v2'\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea06d644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T20:10:26.648376Z",
     "iopub.status.busy": "2024-07-26T20:10:26.648038Z",
     "iopub.status.idle": "2024-07-26T20:10:27.641366Z",
     "shell.execute_reply": "2024-07-26T20:10:27.640499Z"
    },
    "papermill": {
     "duration": 1.000384,
     "end_time": "2024-07-26T20:10:27.643526",
     "exception": false,
     "start_time": "2024-07-26T20:10:26.643142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d17419b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T20:10:27.653139Z",
     "iopub.status.busy": "2024-07-26T20:10:27.652716Z",
     "iopub.status.idle": "2024-07-26T20:24:34.305493Z",
     "shell.execute_reply": "2024-07-26T20:24:34.304368Z"
    },
    "papermill": {
     "duration": 846.660641,
     "end_time": "2024-07-26T20:24:34.308304",
     "exception": false,
     "start_time": "2024-07-26T20:10:27.647663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 20:10:31.911447: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-07-26 20:10:31.911548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-07-26 20:10:32.057991: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Number of devices: 2\r\n",
      "The size of the training set: 945\r\n",
      "The size of the validation set: 237\r\n",
      "Steps/Epoch: 59\r\n",
      "<class 'function'>\r\n",
      "\u001b[1mModel: \"functional\"\u001b[0m\r\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\r\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\r\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\r\n",
      "│ keras_tensor_2CLONE │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ -                 │\r\n",
      "│ (\u001b[94mInputLayer\u001b[0m)        │ \u001b[32m3\u001b[0m)                │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d (\u001b[94mConv2D\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │        \u001b[32m448\u001b[0m │ keras_tensor_2CL… │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]      │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m2,320\u001b[0m │ dropout[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]     │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d       │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_1[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m4,640\u001b[0m │ max_pooling2d[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_1 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_2[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m9,248\u001b[0m │ dropout_1[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d_1     │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_3[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_4 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m18,496\u001b[0m │ max_pooling2d_1[\u001b[32m…\u001b[0m │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_2 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_4[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_5 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m36,928\u001b[0m │ dropout_2[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d_2     │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_5[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_6 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │     \u001b[32m73,856\u001b[0m │ max_pooling2d_2[\u001b[32m…\u001b[0m │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_3 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_6[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_7 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m147,584\u001b[0m │ dropout_3[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ max_pooling2d_3     │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_7[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mMaxPooling2D\u001b[0m)      │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_8 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │    \u001b[32m295,168\u001b[0m │ max_pooling2d_3[\u001b[32m…\u001b[0m │\r\n",
      "│                     │ \u001b[32m256\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_4 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_8[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│                     │ \u001b[32m256\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_9 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m48\u001b[0m, \u001b[32m48\u001b[0m,    │    \u001b[32m590,080\u001b[0m │ dropout_4[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m256\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose    │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m131,200\u001b[0m │ conv2d_9[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m256\u001b[0m)              │            │ conv2d_7[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_10 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m295,040\u001b[0m │ concatenate[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m] │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_5 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │          \u001b[32m0\u001b[0m │ conv2d_10[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_11 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m96\u001b[0m, \u001b[32m96\u001b[0m,    │    \u001b[32m147,584\u001b[0m │ dropout_5[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m128\u001b[0m)              │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose_1  │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m32,832\u001b[0m │ conv2d_11[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m128\u001b[0m)              │            │ conv2d_5[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_12 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m73,792\u001b[0m │ concatenate_1[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_6 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_12[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_13 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m192\u001b[0m, \u001b[32m192\u001b[0m,  │     \u001b[32m36,928\u001b[0m │ dropout_6[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m64\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose_2  │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m8,224\u001b[0m │ conv2d_13[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m64\u001b[0m)               │            │ conv2d_3[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_14 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │     \u001b[32m18,464\u001b[0m │ concatenate_2[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_7 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_14[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_15 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m384\u001b[0m, \u001b[32m384\u001b[0m,  │      \u001b[32m9,248\u001b[0m │ dropout_7[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m32\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_transpose_3  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m2,064\u001b[0m │ conv2d_15[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│ (\u001b[94mConv2DTranspose\u001b[0m)   │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_transpose… │\r\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │ \u001b[32m32\u001b[0m)               │            │ conv2d_1[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]    │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_16 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m4,624\u001b[0m │ concatenate_3[\u001b[32m1\u001b[0m]… │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ dropout_8 (\u001b[94mDropout\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │          \u001b[32m0\u001b[0m │ conv2d_16[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_17 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │      \u001b[32m2,320\u001b[0m │ dropout_8[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m16\u001b[0m)               │            │                   │\r\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\r\n",
      "│ conv2d_18 (\u001b[94mConv2D\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m768\u001b[0m, \u001b[32m768\u001b[0m,  │         \u001b[32m17\u001b[0m │ conv2d_17[\u001b[32m1\u001b[0m][\u001b[32m0\u001b[0m]   │\r\n",
      "│                     │ \u001b[32m1\u001b[0m)                │            │                   │\r\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\r\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m1,941,105\u001b[0m (7.40 MB)\r\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m1,941,105\u001b[0m (7.40 MB)\r\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\r\n",
      "Epoch 1/300\r\n",
      "2024-07-26 20:13:11.989189: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:11.994689: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.005591054s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:16.450288: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:16.461630: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.011435472s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:26.181909: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:26.246099: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.064393254s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:32.484099: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:32.565517: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.081502568s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:37.092647: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:37.223028: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.130484187s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:40.323664: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:40.455913: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.132341602s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:44.748550: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:45.490335: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.741874078s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:48.790592: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:13:49.526579: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.736084906s\r\n",
      "Trying algorithm eng2{k2=0,k3=0} for conv (f32[16,32,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:23.884913: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:24.473928: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.589220129s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:27.990821: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:28.549246: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.558600644s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:34.116830: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:34.595144: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.478396299s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:36.941371: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:14:37.402452: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.461253193s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:01.178672: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:03.282185: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.103621879s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:06.745397: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:08.796940: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.051628311s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,384,384]{3,2,1,0}, f32[16,32,384,384]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:15.194628: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:15.211397: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.016868884s\r\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:16.211565: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:18.973354: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.761870724s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:23.194471: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:23.210869: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.016488604s\r\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:24.211063: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:15:27.539396: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.32841171s\r\n",
      "Trying algorithm eng0{} for conv (f32[16,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,768,768]{3,2,1,0}, f32[16,16,768,768]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "I0000 00:00:1722024937.240913      90 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9150 - dice_score: 0.0100 - loss: 1.21622024-07-26 20:21:27.933617: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:28.058608: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.125166704s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:34.505151: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:34.639381: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.134404391s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,16,768,768]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:45.596176: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:45.647478: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.051419154s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:50.415914: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:21:50.457684: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.041903347s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:41.751067: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:42.814362: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.063474202s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:49.077645: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:50.153815: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.07626921s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,32,384,384]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,384,384]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:52.724333: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:53.004193: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.280031111s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:55.141698: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:22:55.419686: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.278111703s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,384,384]{3,2,1,0}, f32[32,16,2,2]{3,2,1,0}), window={size=2x2 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:03.389074: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:03.515170: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.126303871s\r\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:04.515352: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:05.197099: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.681842383s\r\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:06.197302: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:07.330520: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.133327264s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:14.317627: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:14.442042: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.124513838s\r\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:15.442227: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:16.125245: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.683106024s\r\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:17.125428: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "2024-07-26 20:23:18.257025: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.131684114s\r\n",
      "Trying algorithm eng0{} for conv (f32[32,16,768,768]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,768,768]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\r\n",
      "\r\n",
      "Epoch 1: saving model to models/model.epoch01-val_dice_score0.000.keras\r\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 9s/step - accuracy: 0.9160 - dice_score: 0.0101 - loss: 1.2150 - val_accuracy: 0.9919 - val_dice_score: 2.2144e-09 - val_loss: 1.1257 - learning_rate: 0.0010\r\n",
      "Epoch 2/300\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/airbus_kaggel/./train-model.py\", line 197, in <module>\r\n",
      "    loss_history = [model.fit(model_fit_gen,\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\r\n",
      "    raise e.with_traceback(filtered_tb) from None\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\r\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\r\n",
      "\r\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\r\n",
      "  File \"/kaggle/working/airbus_kaggel/./train-model.py\", line 197, in <module>\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\r\n",
      "\r\n",
      "Out of memory while trying to allocate 12288218104 bytes.\r\n",
      "BufferAssignment OOM Debugging.\r\n",
      "BufferAssignment stats:\r\n",
      "             parameter allocation:  166.21MiB\r\n",
      "              constant allocation:        32B\r\n",
      "        maybe_live_out allocation:   22.21MiB\r\n",
      "     preallocated temp allocation:   11.44GiB\r\n",
      "  preallocated temp fragmentation:  868.42MiB (7.41%)\r\n",
      "                 total allocation:   11.61GiB\r\n",
      "              total fragmentation:  884.06MiB (7.44%)\r\n",
      "Peak buffers:\r\n",
      "\tBuffer 1:\r\n",
      "\t\tSize: 1.12GiB\r\n",
      "\t\tOperator: op_type=\"ConcatV2\" op_name=\"functional_1/concatenate_3_1/concat\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,32,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 2:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 3:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/functional_1/conv2d_18_1/convolution/Conv2DBackpropInput\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 4:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_17_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 5:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"SelectV2\" op_name=\"functional_1/dropout_8_1/stateless_dropout/SelectV2\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160 deduplicated_name=\"fusion.208\"\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 6:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_16_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 7:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"ConcatV2\" op_name=\"functional_1/concatenate_2_1/concat\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,64,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 8:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 9:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"SelectV2\" op_name=\"functional_1/dropout_1/stateless_dropout/SelectV2\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160 deduplicated_name=\"fusion.208\"\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 10:\r\n",
      "\t\tSize: 576.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,16,768,768]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 11:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_15_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 12:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"SelectV2\" op_name=\"functional_1/dropout_7_1/stateless_dropout/SelectV2\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160 deduplicated_name=\"fusion.210\"\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 13:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_14_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 14:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"ConcatV2\" op_name=\"functional_1/concatenate_1_2/concat\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: fusion\r\n",
      "\t\tShape: f32[16,128,192,192]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\tBuffer 15:\r\n",
      "\t\tSize: 288.00MiB\r\n",
      "\t\tOperator: op_type=\"Conv2D\" op_name=\"functional_1/conv2d_3_1/convolution\" source_file=\"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1160\r\n",
      "\t\tXLA Label: custom-call\r\n",
      "\t\tShape: f32[16,32,384,384]\r\n",
      "\t\t==========================\r\n",
      "\r\n",
      "\r\n",
      "\t [[{{node StatefulPartitionedCall}}]]\r\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n",
      " [Op:__inference_one_step_on_iterator_9103]\r\n",
      "2024-07-26 20:24:33.819230: F external/local_tsl/tsl/framework/bfc_allocator.cc:700] Check failed: h != kInvalidChunkHandle \r\n"
     ]
    }
   ],
   "source": [
    "!python ./train-model.py --csv_file /kaggle/input/airbus-kaggle-preprocessed/df.csv --dataset_path /kaggle/input/airbus-ship-detection/train_v2 --max_number_of_samples 1500 --epochs 300 --batch_size 16 --loss_function dice_bce_loss --patch_size 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fcafb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T20:24:34.340522Z",
     "iopub.status.busy": "2024-07-26T20:24:34.340202Z",
     "iopub.status.idle": "2024-07-26T20:24:35.340786Z",
     "shell.execute_reply": "2024-07-26T20:24:35.339830Z"
    },
    "papermill": {
     "duration": 1.018796,
     "end_time": "2024-07-26T20:24:35.343068",
     "exception": false,
     "start_time": "2024-07-26T20:24:34.324272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 49596\r\n",
      "drwxr-xr-x 7 root root     4096 Jul 26 20:12 .\r\n",
      "drwxr-xr-x 3 root root     4096 Jul 26 20:10 ..\r\n",
      "drwxr-xr-x 8 root root     4096 Jul 26 20:10 .git\r\n",
      "-rw-r--r-- 1 root root       43 Jul 26 20:10 .gitignore\r\n",
      "-rw-r--r-- 1 root root     5040 Jul 26 20:10 README.md\r\n",
      "-rw-r--r-- 1 root root 50719787 Jul 26 20:10 df.csv\r\n",
      "drwxr-xr-x 4 root root     4096 Jul 26 20:21 logs\r\n",
      "drwxr-xr-x 2 root root     4096 Jul 26 20:24 models\r\n",
      "drwxr-xr-x 2 root root     4096 Jul 26 20:10 notebooks\r\n",
      "-rw-r--r-- 1 root root      128 Jul 26 20:10 requirements.txt\r\n",
      "-rw-r--r-- 1 root root     2878 Jul 26 20:10 test-model.py\r\n",
      "-rw-r--r-- 1 root root    13222 Jul 26 20:10 train-model.py\r\n",
      "drwxr-xr-x 3 root root     4096 Jul 26 20:10 utils\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 868324,
     "sourceId": 9988,
     "sourceType": "competition"
    },
    {
     "datasetId": 5450343,
     "sourceId": 9040735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 859.247355,
   "end_time": "2024-07-26T20:24:35.577868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-26T20:10:16.330513",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
