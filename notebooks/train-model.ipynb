{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9988,"databundleVersionId":868324,"sourceType":"competition"},{"sourceId":77306,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":64999}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"config.py:\n\n","metadata":{"id":"MZu1fURA5jOV"}},{"cell_type":"code","source":"import os\n\n# change \nMODE = 'train model'\nMODE = 'test model'\n\n# model configs\nNUM_SAMPLES = 3000  # not a total number of samples, but max number of samples with the same 'ship_count'\nVALIDATION_SET_SIZE = 0.1 # number from 0 to 1.0\nGAUSSIAN_NOISE = 0.1\nNB_EPOCHS = 40\nBATCH_SIZE = 64\nPATCH_SIZE = 256\nINPUT_DATA_DIM = (PATCH_SIZE, PATCH_SIZE, 3)\n\n# env_configs\nBASE_DIR = '/kaggle/input/airbus-ship-detection'\nTEST_IMG_DIR = os.path.join(BASE_DIR,'test_v2')\nTRAIN_IMG_DIR = os.path.join(BASE_DIR,'train_v2')\nTRAIN_DATASET_CSV = os.path.join(BASE_DIR,'train_ship_segmentations_v2.csv')\n\n# WEIGHTS_DIR = 'weights'\n# WEIGHTS_FILE = 'model.{epoch:02d}-{val_loss:.2f}.weights.h5'\n# WEIGHTS_PATH = os.path.join(WEIGHTS_DIR, WEIGHTS_FILE)\n\nMODEL_DIR = 'model'\nMODEL_FILE = 'model.{epoch:02d}-{val_loss:.2f}.keras'\nMODEL_PATH = os.path.join(MODEL_DIR, MODEL_FILE)\n\n# model testing configs\nMODEL_TO_TEST = '/kaggle/working/model/model.05-1.08.keras'\n# MODEL_TO_TEST_PATH = os.path.join(MODEL_DIR, MODEL_TO_TEST)\nMODEL_TO_TEST_PATH = os.path.join(MODEL_TO_TEST)","metadata":{"id":"CD82dQDe5qw5","execution":{"iopub.status.busy":"2024-07-13T19:12:25.689388Z","iopub.execute_input":"2024-07-13T19:12:25.689839Z","iopub.status.idle":"2024-07-13T19:12:25.731688Z","shell.execute_reply.started":"2024-07-13T19:12:25.689805Z","shell.execute_reply":"2024-07-13T19:12:25.730576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"utils.py:","metadata":{"id":"QjGWfzv159Y3"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\n\n#utility functions\ndef rle_to_mask(starts, lengths, height, width):\n    # Create an empty array of zeros of shape (height, width)\n    mask = np.zeros(height * width, dtype=np.uint8)\n\n    # For each start and length, set the corresponding values in the mask to 1\n    for start, length in zip(starts, lengths):\n        mask[start:start + length] = 1\n\n    # Reshape the mask into the desired dimensions\n    mask = mask.reshape((height, width))\n    mask = mask.T\n    return mask\n\ndef create_mask(mask_array, width=768, height=768):\n    masks = np.zeros((width, height), dtype=np.int16)\n    # if element == element:\n    if isinstance(mask_array, str):\n        split = mask_array.split()\n        startP, lengthP = [np.array(x, dtype=int) for x in (split[::2], split[1::2])]\n        masks += (rle_to_mask(startP, lengthP, width, height))\n    return masks\n\ndef generate_prediction(model, img_dir, img_name):\n    img = os.path.join(img_dir, img_name)\n    img = Image.open(img)\n    img = np.array(img)\n    img = resize(img, (PATCH_SIZE, PATCH_SIZE), anti_aliasing=True)\n    img = tf.expand_dims(img, axis=0)\n    pred = model.predict(img)\n    print(f\"prediction shape - {pred.shape}\")\n    return pred, img\n\ndef visualise_prediction(model, img_dir, img_name):\n    pred, img = generate_prediction(model, img_dir, img_name)\n    plt.figure(figsize=(10, 10))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img[0])\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(pred[0])\n    plt.title(\"Predicted Mask\")\n    plt.axis(\"off\")\n    plt.show()","metadata":{"id":"Y_nz8dxN6A0C","execution":{"iopub.status.busy":"2024-07-13T19:12:25.733736Z","iopub.execute_input":"2024-07-13T19:12:25.734065Z","iopub.status.idle":"2024-07-13T19:12:35.151279Z","shell.execute_reply.started":"2024-07-13T19:12:25.734038Z","shell.execute_reply":"2024-07-13T19:12:35.150311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"generators.py:","metadata":{"id":"tIf8QwC06IwT"}},{"cell_type":"code","source":"import numpy as np\n\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\ndef img_gen(input_df, batch_size = BATCH_SIZE, patch_size = PATCH_SIZE):\n    # shuffle the dataset\n    input_df = input_df.sample(frac=1, random_state=42).reset_index(drop=True)\n    out_rgb = []\n    out_mask = []\n    while True:\n        for index, row in input_df.iterrows():\n            rgb_path = os.path.join(TRAIN_IMG_DIR, row.ImageId)\n            rgb = Image.open(rgb_path)\n            rgb = np.array(rgb)/255.0\n            rgb = resize(rgb, (patch_size, patch_size), anti_aliasing=True)\n            mask = create_mask(row.AllEncodedPixels)\n            mask = resize(mask, (patch_size, patch_size), anti_aliasing=True)\n#             the next line is 'kostyl' to address min/max mask values beeing equal to 0.0/3.051851e-05\n            mask = np.where(mask > 0, 1, 0)\n            mask = np.expand_dims(mask, -1)\n\n            for i in range(0, rgb.shape[0], patch_size):\n                for j in range(0, rgb.shape[1], patch_size):\n                    single_mask_patch = mask[i:i+patch_size, j:j+patch_size]\n                    if (single_mask_patch.max()):\n                        single_rgb_patch = rgb[i:i+patch_size, j:j+patch_size]\n                        out_rgb += [single_rgb_patch]\n                        out_mask += [single_mask_patch]\n                    if len(out_rgb)>=batch_size:\n                        yield np.stack(out_rgb, 0), np.stack(out_mask, 0).astype(np.float32)\n                        out_rgb, out_mask=[], []\n\n# arhuments for augmentation image generator\ndata_gen_args = dict(rotation_range = 90,\n                       horizontal_flip = True,\n                       vertical_flip = True,\n                       data_format = 'channels_last')\n\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\n# data augmentation generator\ndef augmentation_generator(input_gen, seed = None):\n    random_seed = np.random.randint(0, 10000)\n    for input_x, input_y in input_gen:\n        augmented_x = image_datagen.flow(\n            input_x*255,\n            batch_size=input_x.shape[0],\n            seed=random_seed\n        )\n\n        augmented_y = mask_datagen.flow(\n            input_y,\n            batch_size=input_y.shape[0],\n            seed=random_seed\n        )\n\n        yield next(augmented_x)/255.0, next(augmented_y)\n","metadata":{"id":"VJxf-iT_6KDu","execution":{"iopub.status.busy":"2024-07-13T19:12:35.152661Z","iopub.execute_input":"2024-07-13T19:12:35.153243Z","iopub.status.idle":"2024-07-13T19:12:35.199027Z","shell.execute_reply.started":"2024-07-13T19:12:35.153203Z","shell.execute_reply":"2024-07-13T19:12:35.197813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"losses.py:\n","metadata":{"id":"l_nzSt3_7vQn"}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\n# loss functions\ndef dice_score(y_true, y_pred, smooth=1e-6):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3]  )\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_score(y_true, y_pred)\n\ndef bce_loss(y_true, y_pred):\n    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=[1, 2, 3])\n\ndef dice_bce_loss(y_true, y_pred):\n    dice_loss_value = dice_loss(y_true, y_pred)\n    bce_loss_value = bce_loss(y_true, y_pred)\n    return dice_loss_value + bce_loss_value","metadata":{"id":"Qbm9R-Da7xDJ","execution":{"iopub.status.busy":"2024-07-13T19:12:35.201609Z","iopub.execute_input":"2024-07-13T19:12:35.201988Z","iopub.status.idle":"2024-07-13T19:12:35.212350Z","shell.execute_reply.started":"2024-07-13T19:12:35.201958Z","shell.execute_reply":"2024-07-13T19:12:35.211193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model.py:","metadata":{"id":"ZR4pE49772lx"}},{"cell_type":"code","source":"from tensorflow.keras import layers, Model, Input\n\n\ndef unet(input_shape, optimizer, loss, metrics):\n    inputs = Input(input_shape)\n    inputs = layers.GaussianNoise(GAUSSIAN_NOISE)(inputs)\n    inputs = layers.BatchNormalization()(inputs)\n\n    # Encoder\n    c1 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (inputs)\n    c1 = layers.Dropout(0.1) (c1)\n    c1 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = layers.MaxPooling2D((2, 2)) (c1)\n\n    c2 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = layers.Dropout(0.1) (c2)\n    c2 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = layers.MaxPooling2D((2, 2)) (c2)\n\n    c3 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = layers.Dropout(0.1) (c3)\n    c3 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = layers.MaxPooling2D((2, 2)) (c3)\n\n    c4 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = layers.Dropout(0.1) (c4)\n    c4 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = layers.MaxPooling2D((2, 2)) (c4)\n\n    # Bottleneck\n    c5 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n    c5 = layers.Dropout(0.1) (c5)\n    c5 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n\n    # Decoder\n    u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = layers.concatenate([u6, c4])\n    c6 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = layers.Dropout(0.1) (c6)\n    c6 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = layers.concatenate([u7, c3])\n    c7 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = layers.Dropout(0.1) (c7)\n    c7 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = layers.concatenate([u8, c2])\n    c8 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = layers.Dropout(0.1) (c8)\n    c8 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = layers.concatenate([u9, c1])\n    c9 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = layers.Dropout(0.1) (c9)\n    c9 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n\n    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","metadata":{"id":"e8KWsvOL738v","execution":{"iopub.status.busy":"2024-07-13T19:12:35.213970Z","iopub.execute_input":"2024-07-13T19:12:35.214367Z","iopub.status.idle":"2024-07-13T19:12:35.241664Z","shell.execute_reply.started":"2024-07-13T19:12:35.214328Z","shell.execute_reply":"2024-07-13T19:12:35.240583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train-model.py:","metadata":{"id":"bG-k4yjG79Wq"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n\n\n# Read dataset\ndf = pd.read_csv(TRAIN_DATASET_CSV)\n\n# Add info about whether a ship is present in the image\ndf['has_ship'] = df['EncodedPixels'].apply(lambda x: 0 if pd.isna(x) else 1)\n\n# Add info about the total number of ships in the image\ndf['ship_count'] = df.groupby('ImageId')['EncodedPixels'].transform('count')\n\n# Concatenate all EncodedPixels into AllEncodedPixels\ndf['AllEncodedPixels'] = df.groupby('ImageId')['EncodedPixels'].transform(\n    lambda x: np.nan if x.isna().all() else ' '.join(filter(None, x))\n)\n\n# Remove duplicate images\ndf = df.drop_duplicates(subset='ImageId', keep='first')\n\n# Delete EncodedPixels column\ndf = df.drop(columns=['EncodedPixels'])\n\n# Reset indexes\ndf = df.reset_index(drop=True)\n\n# Create a DataFrame to store the balanced dataset\nbalanced_df = pd.DataFrame()\n\n# Create a balanced dataset\nvalue_counts = df['ship_count'].value_counts()\nfor value in value_counts.index:\n    subset = df[df['ship_count'] == value]\n    number_samples = NUM_SAMPLES if NUM_SAMPLES < len(subset) else len(subset)\n    resampled_subset = resample(subset, replace=False, n_samples=number_samples, random_state=42)\n    balanced_df = pd.concat([balanced_df, resampled_subset])\n\n# Drop images without ships\nbalanced_df = balanced_df[balanced_df['ship_count'] > 0]\n\n# Split the balanced dataset into train and validation sets\ntrain_ids, validation_ids = train_test_split(balanced_df, test_size=VALIDATION_SET_SIZE, stratify=balanced_df['ship_count'])\n\ntrain_df = pd.merge(balanced_df, train_ids)\nvalidation_df = pd.merge(balanced_df, validation_ids)\n\nprint(f\"train_df:\\n {train_df.sample(5)}\")\nprint(f\"validation_df:\\n {validation_df.sample(5)}\")\n\n# Create a generator for training data\ntrain_gen = img_gen(train_df)\n\n# Define callbacks for training\ntensorboard = TensorBoard(log_dir='logs')\n\nearlystopping = EarlyStopping(\n    monitor=\"val_dice_score\",\n    mode=\"max\",\n    patience=15)\n\n# Check if WEIGHTS_DIR exists, if not create it\nif not os.path.exists(MODEL_DIR):\n    os.makedirs(MODEL_DIR)\n\nmodel_path = MODEL_PATH\ncheckpoint = ModelCheckpoint(\n    filepath=model_path,\n    monitor='val_dice_score',\n    verbose=1,\n    mode='max',\n    save_weights_only=False)\n\nreduceLR = ReduceLROnPlateau(\n    monitor='val_dice_score',\n    factor=0.2,\n    patience=3,\n    verbose=1,\n    mode='max',\n    min_delta=0.0001,\n    cooldown=2,\n    min_lr=1e-6)\n\ncallbacks = [tensorboard, earlystopping, checkpoint, reduceLR]\n\n# Calculate the number of steps per epoch\nSTEP_COUNT = train_df.shape[0] // BATCH_SIZE\n\n# Create an augmented generator for model fitting\nmodel_fit_gen = augmentation_generator(img_gen(train_df, BATCH_SIZE, PATCH_SIZE))\n\n# Create a validation set\nvalidation_test_size = (balanced_df.shape[0] - train_df.shape[0])\nvalidation_x, validation_y = next(img_gen(validation_df, validation_test_size, PATCH_SIZE))\n\nprint(f\"The size of the training set: {train_df.shape[0]}\")\nprint(f\"The size of the validation set: {VALIDATION_SET_SIZE}\")\nprint(f\"Steps/Epoch: {STEP_COUNT}\")\n\n# Create a MirroredStrategy for distributed training\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n\n# Open a strategy scope\nwith strategy.scope():\n    # Create the model using the unet function\n    model = unet(INPUT_DATA_DIM, optimizer='adam', loss=dice_bce_loss, metrics=[dice_score])\n    model.summary()\n\n    # Train the model on all available devices\n    loss_history = [model.fit(\n                    model_fit_gen,\n                    steps_per_epoch=STEP_COUNT,\n                    epochs=NB_EPOCHS,\n                    validation_data=(validation_x, validation_y),\n                    callbacks=callbacks)]\n","metadata":{"id":"yGDOLAwo7-5c","execution":{"iopub.status.busy":"2024-07-13T19:12:35.243400Z","iopub.execute_input":"2024-07-13T19:12:35.243792Z"},"trusted":true},"execution_count":null,"outputs":[]}]}